{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html)\n",
    "\n",
    "What is few-shot learning?\n",
    "- It is a technique that can help guide the model's generation and improve performance in some cases. \n",
    "\n",
    "- It is a way to provide a language model with a few example inputs and outputs as part of prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHuman:What do you know about France?\\nAI:\\n    I know this:\\n    Capital: Paris\\n    Language: French\\n    Food: Wine and Cheese\\n    Currency: Euro\\n    \\n\\n\\n\\nHuman:What do you know about Italy?\\nAI:\\n    I know this:\\n    Capital: Rome\\n    Language: Italian\\n    Food: Pizza and Pasta\\n    Currency: Euro\\n    \\n\\n\\n\\nHuman:What do you know about Greece?\\nAI:\\n    I know this:\\n    Capital: Athens\\n    Language: Greek\\n    Food: Souvlaki and Feta Cheese\\n    Currency: Euro\\n    \\n\\n\\nHuman: what do you know about Germany'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "examples = [\n",
    "    {\"question\":\"What do you know about France?\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital: Paris\n",
    "    Language: French\n",
    "    Food: Wine and Cheese\n",
    "    Currency: Euro\n",
    "    \"\"\"},\n",
    "\n",
    "    {\"question\":\"What do you know about Italy?\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital: Rome\n",
    "    Language: Italian\n",
    "    Food: Pizza and Pasta\n",
    "    Currency: Euro\n",
    "    \"\"\"},\n",
    "\n",
    "    {\"question\":\"What do you know about Greece?\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital: Athens\n",
    "    Language: Greek\n",
    "    Food: Souvlaki and Feta Cheese\n",
    "    Currency: Euro\n",
    "    \"\"\"}\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "Human:{question}\n",
    "AI:{answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"Human: what do you know about {country}\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "few_shot_prompt.format(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [FewShotChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate \n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"country\":\"France\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital: Paris\n",
    "    Language: French\n",
    "    Food: Wine and Cheese\n",
    "    Currency: Euro\n",
    "    \"\"\"},\n",
    "\n",
    "    {\"country\":\"What do you know about Italy?\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital: Rome\n",
    "    Language: Italian\n",
    "    Food: Pizza and Pasta\n",
    "    Currency: Euro\n",
    "    \"\"\"},\n",
    "\n",
    "    {\"country\":\"What do you know about Greece?\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital: Athens\n",
    "    Language: Greek\n",
    "    Food: Souvlaki and Feta Cheese\n",
    "    Currency: Euro\n",
    "    \"\"\"}\n",
    "]\n",
    "\n",
    "example_prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What do you know about {country}?\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "few_shot_chat_message_example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "few_shot_chat_message_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a geography expert, you give short answers. And do not generate other messages not explicitly asked.\"),\n",
    "        few_shot_chat_message_example_prompt,\n",
    "        (\"human\", \"What do you know about {country}?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples using Hugging Face Models\n",
    "\n",
    "We can leverage the hugging face models to build LLM apps using [langchain_huggingface](https://python.langchain.com/api_reference/huggingface/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dotenv\n",
    "sec_key = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = dotenv.get_key(\"./.env\", \"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [HuggingFaceEndpoint](https://python.langchain.com/api_reference/huggingface/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/cjung-mo/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id = \"google/gemma-2-2b-it\"\n",
    "# repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, \n",
    "    # model_kwargs={\"max_new_token\":128, \"token\":sec_key}, \n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ],\n",
    "    temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generative AI is a type of artificial intelligence that focuses on creating new content, rather than just analyzing or classifying existing data. It's like having a creative partner that can generate text, images, music, code, and even 3D models based on your prompts and instructions.\n",
      "\n",
      "Here's a breakdown of what makes Generative AI unique:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Learning from Data:** Generative AI models are trained on massive datasets, learning patterns, relationships, and structures within that data.\n",
      "* **Creating New Content:**  Based on this learned knowledge, they can generate entirely new content that resembles the data they were trained on.\n",
      "* **Adaptability:** Generative AI can adapt to different styles, genres, and formats, allowing for diverse and creative outputs.\n",
      "\n",
      "**Examples of Generative AI in Action:**\n",
      "\n",
      "* **Text Generation:** ChatGPT, Bard, Jasper, and other AI writing assistants can generate articles, stories, poems, and even code.\n",
      "* **Image Generation:** DALL-E 2, Midjourney, Stable Diffusion, and others can create realistic and imaginative images from text descriptions.\n",
      "* **Music Generation:** Jukebox, Amper Music, and others can compose original music in various styles.\n",
      "* **Code Generation:** GitHub Copilot and other AI coding assistants can generate code snippets and complete functions.\n",
      "\n",
      "**Benefits of Generative AI:**\n",
      "\n",
      "* **Increased Creativity:**  Generative AI can help overcome creative blocks and generate novel ideas.\n",
      "* **Efficiency:**  It can automate tasks like writing, designing, and coding, saving time and resources.\n",
      "* **Personalization:**  It can create tailored content for specific audiences and preferences.\n",
      "* **Innovation:**  It can drive innovation by exploring new possibilities and pushing the boundaries of creativity.\n",
      "\n",
      "**Challenges of Generative AI:**\n",
      "\n",
      "* **Bias and Fairness:**  AI models can inherit biases from the data they are trained on, leading to unfair or discriminatory outputs.\n",
      "* **Misinformation:**  Generative AI can be used to create fake news, deepfakes, and other forms of misinformation.\n",
      "* **Copyright and Ownership:**  The legal implications of using AI-generated content are still being debated.\n",
      "\n",
      "\n",
      "Generative AI is a rapidly evolving field with the potential to revolutionize many industries. As the technology continues to advance, we can expect to see even more creative and innovative applications emerge. \n",
      "<end_of_turn>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nGenerative AI is a type of artificial intelligence that focuses on creating new content, rather than just analyzing or classifying existing data. It's like having a creative partner that can generate text, images, music, code, and even 3D models based on your prompts and instructions.\\n\\nHere's a breakdown of what makes Generative AI unique:\\n\\n**Key Features:**\\n\\n* **Learning from Data:** Generative AI models are trained on massive datasets, learning patterns, relationships, and structures within that data.\\n* **Creating New Content:**  Based on this learned knowledge, they can generate entirely new content that resembles the data they were trained on.\\n* **Adaptability:** Generative AI can adapt to different styles, genres, and formats, allowing for diverse and creative outputs.\\n\\n**Examples of Generative AI in Action:**\\n\\n* **Text Generation:** ChatGPT, Bard, Jasper, and other AI writing assistants can generate articles, stories, poems, and even code.\\n* **Image Generation:** DALL-E 2, Midjourney, Stable Diffusion, and others can create realistic and imaginative images from text descriptions.\\n* **Music Generation:** Jukebox, Amper Music, and others can compose original music in various styles.\\n* **Code Generation:** GitHub Copilot and other AI coding assistants can generate code snippets and complete functions.\\n\\n**Benefits of Generative AI:**\\n\\n* **Increased Creativity:**  Generative AI can help overcome creative blocks and generate novel ideas.\\n* **Efficiency:**  It can automate tasks like writing, designing, and coding, saving time and resources.\\n* **Personalization:**  It can create tailored content for specific audiences and preferences.\\n* **Innovation:**  It can drive innovation by exploring new possibilities and pushing the boundaries of creativity.\\n\\n**Challenges of Generative AI:**\\n\\n* **Bias and Fairness:**  AI models can inherit biases from the data they are trained on, leading to unfair or discriminatory outputs.\\n* **Misinformation:**  Generative AI can be used to create fake news, deepfakes, and other forms of misinformation.\\n* **Copyright and Ownership:**  The legal implications of using AI-generated content are still being debated.\\n\\n\\nGenerative AI is a rapidly evolving field with the potential to revolutionize many industries. As the technology continues to advance, we can expect to see even more creative and innovative applications emerge. \\n<end_of_turn>\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is Generative AI?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template=\"\\nQuestion: {question}\\nAnswer: Let's think step by step.\\n\")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Question: {question}\n",
    "Answer: Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* **What is the Republic of Korea?**  It is also known as South Korea.\n",
      "* **Who is the current president of South Korea?** It is Yoon Suk-yeol. \n",
      "\n",
      "**Therefore, the 18th president of the Republic of Korea is Yoon Suk-yeol.** \n",
      "<end_of_turn>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'* **What is the Republic of Korea?**  It is also known as South Korea.\\n* **Who is the current president of South Korea?** It is Yoon Suk-yeol. \\n\\n**Therefore, the 18th president of the Republic of Korea is Yoon Suk-yeol.** \\n<end_of_turn>'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke(\"Who is the 18th president of Republic of Korea?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['country'] input_types={} partial_variables={} examples=[{'question': 'What do you know about France?', 'answer': '\\n    I know this:\\n    Capital: Paris\\n    Language: French\\n    Food: Wine and Cheese\\n    Currency: Euro\\n    '}, {'question': 'What do you know about Italy?', 'answer': '\\n    I know this:\\n    Capital: Rome\\n    Language: Italian\\n    Food: Pizza and Pasta\\n    Currency: Euro\\n    '}, {'question': 'What do you know about Greece?', 'answer': '\\n    I know this:\\n    Capital: Athens\\n    Language: Greek\\n    Food: Souvlaki and Feta Cheese\\n    Currency: Euro\\n    '}] example_prompt=PromptTemplate(input_variables=['answer', 'question'], input_types={}, partial_variables={}, template='\\nHuman:{question}\\nAI:{answer}\\n') suffix='Human: what do you know about {country}'\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Berlin\n",
      "    Language: German\n",
      "    Food: Bratwurst and Sauerkraut\n",
      "    Currency: Euro\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about Spain?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Madrid\n",
      "    Language: Spanish\n",
      "    Food: Paella and Tapas\n",
      "    Currency: Euro\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about Japan?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Tokyo\n",
      "    Language: Japanese\n",
      "    Food: Sushi and Ramen\n",
      "    Currency: Yen\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about China?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Beijing\n",
      "    Language: Mandarin Chinese\n",
      "    Food: Dumplings and Noodles\n",
      "    Currency: Yuan\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about Brazil?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Brasilia\n",
      "    Language: Portuguese\n",
      "    Food: Feijoada and Churrasco\n",
      "    Currency: Real\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about Canada?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Ottawa\n",
      "    Language: English and French\n",
      "    Food: Poutine and Maple Syrup\n",
      "    Currency: Canadian Dollar\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about Russia?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Moscow\n",
      "    Language: Russian\n",
      "    Food: Borscht and Pelmeni\n",
      "    Currency: Ruble\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about Mexico?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Mexico City\n",
      "    Language: Spanish\n",
      "    Food: Tacos and Enchiladas\n",
      "    Currency: Peso\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about Australia?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Canberra\n",
      "    Language: English\n",
      "    Food: Vegemite and Pavlova\n",
      "    Currency: Australian Dollar\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about India?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: New Delhi\n",
      "    Language: Hindi\n",
      "    Food: Curry and Naan\n",
      "    Currency: Rupee\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about South Africa?\n",
      "AI:\n",
      "    I know this:\n",
      "    Capital: Pretoria\n",
      "    Language: Afrikaans and English\n",
      "    Food: Biltong and Braai\n",
      "    Currency: Rand\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Human: What do you know about Argentina?\n",
      "AI:\n",
      "    I"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'?\\nAI:\\n    I know this:\\n    Capital: Berlin\\n    Language: German\\n    Food: Bratwurst and Sauerkraut\\n    Currency: Euro\\n    \\n\\n\\n\\nHuman: What do you know about Spain?\\nAI:\\n    I know this:\\n    Capital: Madrid\\n    Language: Spanish\\n    Food: Paella and Tapas\\n    Currency: Euro\\n    \\n\\n\\n\\nHuman: What do you know about Japan?\\nAI:\\n    I know this:\\n    Capital: Tokyo\\n    Language: Japanese\\n    Food: Sushi and Ramen\\n    Currency: Yen\\n    \\n\\n\\n\\nHuman: What do you know about China?\\nAI:\\n    I know this:\\n    Capital: Beijing\\n    Language: Mandarin Chinese\\n    Food: Dumplings and Noodles\\n    Currency: Yuan\\n    \\n\\n\\n\\nHuman: What do you know about Brazil?\\nAI:\\n    I know this:\\n    Capital: Brasilia\\n    Language: Portuguese\\n    Food: Feijoada and Churrasco\\n    Currency: Real\\n    \\n\\n\\n\\nHuman: What do you know about Canada?\\nAI:\\n    I know this:\\n    Capital: Ottawa\\n    Language: English and French\\n    Food: Poutine and Maple Syrup\\n    Currency: Canadian Dollar\\n    \\n\\n\\n\\nHuman: What do you know about Russia?\\nAI:\\n    I know this:\\n    Capital: Moscow\\n    Language: Russian\\n    Food: Borscht and Pelmeni\\n    Currency: Ruble\\n    \\n\\n\\n\\nHuman: What do you know about Mexico?\\nAI:\\n    I know this:\\n    Capital: Mexico City\\n    Language: Spanish\\n    Food: Tacos and Enchiladas\\n    Currency: Peso\\n    \\n\\n\\n\\nHuman: What do you know about Australia?\\nAI:\\n    I know this:\\n    Capital: Canberra\\n    Language: English\\n    Food: Vegemite and Pavlova\\n    Currency: Australian Dollar\\n    \\n\\n\\n\\nHuman: What do you know about India?\\nAI:\\n    I know this:\\n    Capital: New Delhi\\n    Language: Hindi\\n    Food: Curry and Naan\\n    Currency: Rupee\\n    \\n\\n\\n\\nHuman: What do you know about South Africa?\\nAI:\\n    I know this:\\n    Capital: Pretoria\\n    Language: Afrikaans and English\\n    Food: Biltong and Braai\\n    Currency: Rand\\n    \\n\\n\\n\\nHuman: What do you know about Argentina?\\nAI:\\n    I'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = few_shot_prompt | llm\n",
    "chain.invoke({\"country\":\"Germany\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Chat Message Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['country'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a geography expert, you give short answers. and do not generate other message not asked'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'country': 'France', 'answer': '\\n    I know this:\\n    Capital: Paris\\n    Language: French\\n    Food: Wine and Cheese\\n    Currency: Euro\\n    '}, {'country': 'What do you know about Italy?', 'answer': '\\n    I know this:\\n    Capital: Rome\\n    Language: Italian\\n    Food: Pizza and Pasta\\n    Currency: Euro\\n    '}, {'country': 'What do you know about Greece?', 'answer': '\\n    I know this:\\n    Capital: Athens\\n    Language: Greek\\n    Food: Souvlaki and Feta Cheese\\n    Currency: Euro\\n    '}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['answer', 'country'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What do you know about {country}?'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['answer'], input_types={}, partial_variables={}, template='{answer}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What do you know about {country}?'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_chat_message_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: \n",
      "    I know this:\n",
      "    Capital: Seoul\n",
      "    Language: Korean\n",
      "    Food: Kimchi and Bibimbap\n",
      "    Currency: Won\n",
      "<end_of_turn>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAI: \\n    I know this:\\n    Capital: Seoul\\n    Language: Korean\\n    Food: Kimchi and Bibimbap\\n    Currency: Won\\n<end_of_turn>'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = few_shot_chat_message_prompt | llm \n",
    "chain.invoke({\n",
    "    \"country\":\"South Korea\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [HuggingFacePipeline](https://python.langchain.com/api_reference/huggingface/llms/langchain_huggingface.llms.huggingface_pipeline.HuggingFacePipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2007853a34304adc90ce755c305ce7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621dc7b23c4e48739d5bbd40ffb945b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bfbc222edf410588aef100fa29005b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85227351d904f5887eb3c34353bf60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551cc5f26ebf45768deb8be9f3cc8cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec07868cb6a2480fb1272dcfc630938e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c5dbf42ef14f1e9b19349b023a96f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# model_id=\"google/gemma-2-2b-it\"\n",
    "model_id=\"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=128,\n",
    ")\n",
    "\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'System: You are a geography expert, you give short answers. And do not generate other messages not explicitly asked.\\nHuman: What do you know about France?\\nAI: \\n    I know this:\\n    Capital: Paris\\n    Language: French\\n    Food: Wine and Cheese\\n    Currency: Euro\\n    \\nHuman: What do you know about What do you know about Italy??\\nAI: \\n    I know this:\\n    Capital: Rome\\n    Language: Italian\\n    Food: Pizza and Pasta\\n    Currency: Euro\\n    \\nHuman: What do you know about What do you know about Greece??\\nAI: \\n    I know this:\\n    Capital: Athens\\n    Language: Greek\\n    Food: Souvlaki and Feta Cheese\\n    Currency: Euro\\n    \\nHuman: What do you know about Germany?\\nAI:  (No one else is here)\\nHuman: What do you know about Poland??\\nAI:  (No one else is here)\\nHuman: What do you know about Germany?\\nhuman:  (No one else is here)\\nHuman: What do you know about Germany?\\nHuman:  (Yes)\\nHuman, here are others:\\n#1: English\\nHuman, here are other immigrants\\nHuman, there are people here who also are here:\\nHuman, I am here because I want to help others.\\nI am not interested in help for the others because I do not'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = few_shot_chat_message_prompt | hf\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\":\"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LengthBasedExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.length_based.LengthBasedExampleSelector.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHuman:What do you know about France?\\nAI:\\n    I know this:\\n    Capital: Paris\\n    Language: French\\n    Food: Wine and Cheese\\n    Currency: Euro\\n    \\n\\n\\nHuman: what do you know about Brazil'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.example_selectors.length_based import LengthBasedExampleSelector \n",
    "\n",
    "examples = [\n",
    "    {\"question\":\"What do you know about France?\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital: Paris\n",
    "    Language: French\n",
    "    Food: Wine and Cheese\n",
    "    Currency: Euro\n",
    "    \"\"\"},\n",
    "\n",
    "    {\"question\":\"What do you know about Italy?\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital: Rome\n",
    "    Language: Italian\n",
    "    Food: Pizza and Pasta\n",
    "    Currency: Euro\n",
    "    \"\"\"},\n",
    "\n",
    "    {\"question\":\"What do you know about Greece?\",\n",
    "    \"answer\":\"\"\"\n",
    "    I know this:\n",
    "    Capital: Athens\n",
    "    Language: Greek\n",
    "    Food: Souvlaki and Feta Cheese\n",
    "    Currency: Euro\n",
    "    \"\"\"}\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "Human:{question}\n",
    "AI:{answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=80\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: what do you know about {country}\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "few_shot_prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomExampleSelector \n",
    "\n",
    "Implement RandomExampleSelector that selects randomly from the examples list, this class is inherited from [BaseExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHuman:What do you know about Greece?\\nAI:\\n    I know this:\\n    Capital: Athens\\n    Language: Greek\\n    Food: Souvlaki and Feta Cheese\\n    Currency: Euro\\n    \\n\\n\\nHuman: what do you know about Brazil'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.example_selectors.base import BaseExampleSelector\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "example_template = \"\"\"\n",
    "Human:{question}\n",
    "AI:{answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: what do you know about {country}\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "few_shot_prompt.format(country=\"Brazil\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
